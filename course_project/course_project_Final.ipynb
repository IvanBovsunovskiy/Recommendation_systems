{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основное**\n",
    "- Дедлайн - 19 февраля 23:59\n",
    "- Целевая метрика precision@5\n",
    "- Бейзлайн решения - [MainRecommender](https://github.com/geangohn/recsys-tutorial/blob/master/src/recommenders.py)\n",
    "- Сдаем ссылку на github с решением. В решении должны быть отчетливо видна метрика на новом тестовом сете из файла retail_test1.csv, то есть вам нужно для всех юзеров из этого файла выдать выши рекомендации, и посчитать на actual покупках precision@5. \n",
    "\n",
    "**!! Мы не рассматриваем холодный старт для пользователя, все наши пользователя одинаковы во всех сетах, поэтому нужно позаботиться об их исключении из теста.**\n",
    "\n",
    "\n",
    "**Hints:** \n",
    "\n",
    "Сначала просто попробуйте разные параметры MainRecommender:  \n",
    "- N в топ-N товарах при формировании user-item матирцы (сейчас топ-5000)  \n",
    "- Различные веса в user-item матрице (0/1, кол-во покупок, log(кол-во покупок + 1), сумма покупки, ...)  \n",
    "- Разные взвешивания матрицы (TF-IDF, BM25 - у него есть параметры)  \n",
    "- Разные смешивания рекомендаций (обратите внимание на бейзлайн - прошлые покупки юзера)  \n",
    "\n",
    "Сделайте MVP - минимально рабочий продукт - (пусть даже top-popular), а потом его улучшайте\n",
    "\n",
    "Если вы делаете двухуровневую модель - следите за валидацией "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit import als\n",
    "\n",
    "# Модель второго уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Написанные нами функции\n",
    "from metrics import precision_at_k, recall_at_k\n",
    "from utils import prefilter_items\n",
    "from recommenders import MainRecommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('retail_train.csv')\n",
    "item_features = pd.read_csv('product.csv')\n",
    "user_features = pd.read_csv('hh_demographic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1036325</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1082185</td>\n",
       "      <td>1</td>\n",
       "      <td>1.21</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>8160430</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "2     2375  26984851472    1  1036325         1         0.99       364   \n",
       "3     2375  26984851472    1  1082185         1         1.21       364   \n",
       "4     2375  26984851472    1  8160430         1         1.50       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0        -0.60        1631        1          0.0                0.0  \n",
       "1         0.00        1631        1          0.0                0.0  \n",
       "2        -0.30        1631        1          0.0                0.0  \n",
       "3         0.00        1631        1          0.0                0.0  \n",
       "4        -0.39        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set global const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_COL = 'item_id'\n",
    "USER_COL = 'user_id'\n",
    "ACTUAL_COL = 'actual'\n",
    "\n",
    "# N = Neighbors\n",
    "N_PREDICT = 110 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': ITEM_COL}, inplace=True)\n",
    "user_features.rename(columns={'household_key': USER_COL }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset for train, eval, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важна схема обучения и валидации!\n",
    "# -- давние покупки -- | -- 7 недель -- | -- 4 недель -- \n",
    "# подобрать размер 2-ого датасета (7 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
    "VAL_MATCHER_WEEKS = 11\n",
    "VAL_RANKER_WEEKS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# берем данные для тренировки matching модели\n",
    "data_train_matcher = data[data['week_no'] < data['week_no'].max() - (VAL_MATCHER_WEEKS + VAL_RANKER_WEEKS)]\n",
    "\n",
    "# берем данные для валидации matching модели\n",
    "data_val_matcher = data[(data['week_no'] >= data['week_no'].max() - (VAL_MATCHER_WEEKS + VAL_RANKER_WEEKS)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (VAL_RANKER_WEEKS))]\n",
    "\n",
    "# берем данные для тренировки ranking модели\n",
    "data_train_ranker = data_val_matcher.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "\n",
    "# берем данные для теста ranking, matching модели\n",
    "data_val_ranker = data[data['week_no'] >= data['week_no'].max() - VAL_RANKER_WEEKS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем объединенный сет данных для первого уровня (матчинга)\n",
    "df_join_train_matcher = pd.concat([data_train_matcher, data_val_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats_data(df_data, name_df):\n",
    "    print(name_df)\n",
    "    print(f\"Shape: {df_data.shape} Users: {df_data[USER_COL].nunique()} Items: {df_data[ITEM_COL].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_matcher\n",
      "Shape: (1968369, 12) Users: 2498 Items: 80902\n",
      "val_matcher\n",
      "Shape: (310121, 12) Users: 2293 Items: 35272\n",
      "train_ranker\n",
      "Shape: (310121, 12) Users: 2293 Items: 35272\n",
      "val_ranker\n",
      "Shape: (118314, 12) Users: 2042 Items: 24329\n"
     ]
    }
   ],
   "source": [
    "print_stats_data(data_train_matcher,'train_matcher')\n",
    "print_stats_data(data_val_matcher,'val_matcher')\n",
    "print_stats_data(data_train_ranker,'train_ranker')\n",
    "print_stats_data(data_val_ranker,'val_ranker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выше видим разброс по пользователям и товарам и дальше мы перейдем к warm-start (только известные пользователи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1963047</th>\n",
       "      <td>2375</td>\n",
       "      <td>40186322971</td>\n",
       "      <td>559</td>\n",
       "      <td>827667</td>\n",
       "      <td>2</td>\n",
       "      <td>6.00</td>\n",
       "      <td>364</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963048</th>\n",
       "      <td>2375</td>\n",
       "      <td>40186322971</td>\n",
       "      <td>559</td>\n",
       "      <td>834631</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "1963047     2375  40186322971  559   827667         2         6.00       364   \n",
       "1963048     2375  40186322971  559   834631         1         1.69       364   \n",
       "\n",
       "         retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "1963047        -1.78          34       81          0.0                0.0  \n",
       "1963048         0.00          34       81          0.0                0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_matcher.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefilter items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanbovsunovskii/Downloads/course_project (1)/utils.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['price'] = data['sales_value'] / (np.maximum(data['quantity'], 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 80902 to 1501\n"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train_matcher['item_id'].nunique()\n",
    "\n",
    "n_popular = 1500\n",
    "\n",
    "data_train_matcher = prefilter_items(data_train_matcher, item_features=item_features, take_n_popular=n_popular)\n",
    "\n",
    "n_items_after = data_train_matcher['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make cold-start to warm-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_matcher\n",
      "Shape: (739351, 13) Users: 1981 Items: 1501\n",
      "val_matcher\n",
      "Shape: (297421, 12) Users: 1981 Items: 34563\n",
      "train_ranker\n",
      "Shape: (297421, 12) Users: 1981 Items: 34563\n",
      "val_ranker\n",
      "Shape: (117148, 12) Users: 1981 Items: 24216\n"
     ]
    }
   ],
   "source": [
    "# ищем общих пользователей\n",
    "common_users = list(set(data_train_matcher.user_id.values)&(set(data_val_matcher.user_id.values))&set(data_val_ranker.user_id.values))\n",
    "\n",
    "#выбираем товары из подготовленного набора\n",
    "prefiltered_items = list(set(data_train_matcher['item_id']))\n",
    "\n",
    "# оставляем общих пользователей\n",
    "data_train_matcher = data_train_matcher[data_train_matcher.user_id.isin(common_users)]\n",
    "data_val_matcher = data_val_matcher[data_val_matcher.user_id.isin(common_users)]\n",
    "data_train_ranker = data_train_ranker[data_train_ranker.user_id.isin(common_users)]\n",
    "data_val_ranker = data_val_ranker[data_val_ranker.user_id.isin(common_users)]\n",
    "\n",
    "#оставляем подготовленные товары по всем массивам данных\n",
    "#data_val_matcher = data_val_matcher[data_val_matcher.item_id.isin(prefiltered_items)]\n",
    "#data_train_ranker = data_train_ranker[data_train_ranker.item_id.isin(prefiltered_items)]\n",
    "#data_val_ranker = data_val_ranker[data_val_ranker.item_id.isin(prefiltered_items)]\n",
    "\n",
    "\n",
    "print_stats_data(data_train_matcher,'train_matcher')\n",
    "print_stats_data(data_val_matcher,'val_matcher')\n",
    "print_stats_data(data_train_ranker,'train_ranker')\n",
    "print_stats_data(data_val_ranker,'val_ranker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851516</td>\n",
       "      <td>1</td>\n",
       "      <td>1085983</td>\n",
       "      <td>1</td>\n",
       "      <td>2.99</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1642</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1364</td>\n",
       "      <td>26984896261</td>\n",
       "      <td>1</td>\n",
       "      <td>999999</td>\n",
       "      <td>1</td>\n",
       "      <td>2.19</td>\n",
       "      <td>31742</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1520</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1364</td>\n",
       "      <td>26984896261</td>\n",
       "      <td>1</td>\n",
       "      <td>999999</td>\n",
       "      <td>1</td>\n",
       "      <td>2.99</td>\n",
       "      <td>31742</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1520</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1364</td>\n",
       "      <td>26984896261</td>\n",
       "      <td>1</td>\n",
       "      <td>999999</td>\n",
       "      <td>1</td>\n",
       "      <td>3.09</td>\n",
       "      <td>31742</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1520</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1364</td>\n",
       "      <td>26984896261</td>\n",
       "      <td>1</td>\n",
       "      <td>999999</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>31742</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>1520</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "7      2375  26984851516    1  1085983         1         2.99       364   \n",
       "11     1364  26984896261    1   999999         1         2.19     31742   \n",
       "12     1364  26984896261    1   999999         1         2.99     31742   \n",
       "13     1364  26984896261    1   999999         1         3.09     31742   \n",
       "14     1364  26984896261    1   999999         1         2.50     31742   \n",
       "\n",
       "    retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  price  \n",
       "7         -0.40        1642        1          0.0                0.0   2.99  \n",
       "11         0.00        1520        1          0.0                0.0   2.19  \n",
       "12        -0.40        1520        1          0.0                0.0   2.99  \n",
       "13         0.00        1520        1          0.0                0.0   3.09  \n",
       "14        -0.99        1520        1          0.0                0.0   2.50  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_matcher.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init/train recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f40da5e0de442eb9032a2f1f8743fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6275104c818d49f9bb59936361c40498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommender = MainRecommender(data_train_matcher, weighting='bm25', B=0.895, \n",
    "                              n_factors=200, regularization=0.001, iterations=35, num_threads=4, \n",
    "                              K=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Варианты, как получить кандидатов\n",
    "\n",
    "Можно потом все эти варианты соединить в один\n",
    "\n",
    "(!) Если модель рекомендует < N товаров, то рекомендации дополняются топ-популярными товарами до N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval recall of matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Измеряем recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[840361, 856942, 857006, 859676, 868006, 87737...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[833723, 843744, 844839, 910032, 913210, 92134...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [840361, 856942, 857006, 859676, 868006, 87737...\n",
       "1        3  [833723, 843744, 844839, 910032, 913210, 92134..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_eval_matcher = data_val_matcher.groupby(USER_COL)[ITEM_COL].unique().reset_index()\n",
    "result_eval_matcher.columns=[USER_COL, ACTUAL_COL]\n",
    "result_eval_matcher.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommended_items(calc_type, users_list, number_items, function):\n",
    "    if calc_type == 0:\n",
    "        return [function(user, number_items) for user in users_list]\n",
    "    elif calc_type == 1:\n",
    "        return users_list.apply(lambda x: function(x, N=number_items))\n",
    "    else:\n",
    "        return list(map(lambda x: function(x, N=number_items), users_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_eval_matcher['own_rec'] = recommended_items(0, result_eval_matcher[USER_COL], N_PREDICT, recommender.get_own_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример оборачивания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalRecall(df_result, target_col_name, recommend_model, result_col_name='result', \n",
    "               actual_col = 'actual', N_PREDICT=50, inplace = False):\n",
    "    df_result[result_col_name] = recommended_items(0, df_result[target_col_name], N_PREDICT, recommend_model)\n",
    "    result = np.mean([recall_at_k(a, b, k=N_PREDICT) for a,b in zip(df_result[result_col_name], df_result[actual_col])])\n",
    "    if not(inplace):\n",
    "        df_result.drop(columns=result_col_name, inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalPrecision(df_result, target_col_name, recommend_model, result_col_name='result', \n",
    "                  actual_col = 'actual', N_PREDICT=50, inplace = False):\n",
    "    df_result[result_col_name] = recommended_items(0, df_result[target_col_name], N_PREDICT, recommend_model)\n",
    "    result = np.mean([precision_at_k(a, b, k=N_PREDICT) for a,b in zip(df_result[result_col_name], df_result[actual_col])])\n",
    "    if not(inplace):\n",
    "        df_result.drop(columns=result_col_name, inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalRecall(result_eval_matcher, USER_COL, recommender.get_own_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_recall(df_data, top_k):\n",
    "    for col_name in df_data.columns[2:]:\n",
    "        yield col_name, df_data.apply(lambda row: recall_at_k(row[col_name], row[ACTUAL_COL], k=top_k), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision(df_data, top_k):\n",
    "    for col_name in df_data.columns[2:]:\n",
    "        yield col_name, df_data.apply(lambda row: precision_at_k(row[col_name], row[ACTUAL_COL], k=top_k), axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall@50 of matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK_RECALL = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sorted(calc_recall(result_eval_matcher, TOPK_RECALL), key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision@5 of matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK_PRECISION = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(calc_precision(result_eval_matcher, TOPK_PRECISION), key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем модель 2-ого уровня на выбранных кандидатах\n",
    "\n",
    "- Обучаем на data_train_ranking\n",
    "- Обучаем *только* на выбранных кандидатах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- давние покупки -- | -- 7 недель -- | -- 4 недель -- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для трейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# взяли пользователей из трейна для ранжирования\n",
    "df_match_candidates = pd.DataFrame(data_train_ranker[USER_COL].unique())\n",
    "df_match_candidates.columns = [USER_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем кандитатов с первого этапа (matcher)\n",
    "#df_match_candidates['candidates'] = recommended_items(0, df_match_candidates[USER_COL], N_PREDICT, recommender.get_own_recommendations)\n",
    "df_match_candidates['candidates'] = recommended_items(0, df_match_candidates[USER_COL], N_PREDICT, recommender.get_als_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>[1046545, 999104, 1000753, 899624, 902172, 101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>989</td>\n",
       "      <td>[8090509, 985999, 957951, 1020581, 893018, 880...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                         candidates\n",
       "0     2375  [1046545, 999104, 1000753, 899624, 902172, 101...\n",
       "1      989  [8090509, 985999, 957951, 1020581, 893018, 880..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match_candidates.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разворачиваем товары\n",
    "df_items = df_match_candidates.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "df_items.name = 'item_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_candidates = df_match_candidates.drop('candidates', axis=1).join(df_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_match_candidates.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_candidates\n",
      "Shape: (217910, 2) Users: 1981 Items: 1482\n"
     ]
    }
   ],
   "source": [
    "print_stats_data(df_match_candidates, 'match_candidates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем трейн сет для ранжирования с учетом кандидатов с этапа 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1963047</th>\n",
       "      <td>2375</td>\n",
       "      <td>40186322971</td>\n",
       "      <td>559</td>\n",
       "      <td>827667</td>\n",
       "      <td>2</td>\n",
       "      <td>6.00</td>\n",
       "      <td>364</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963048</th>\n",
       "      <td>2375</td>\n",
       "      <td>40186322971</td>\n",
       "      <td>559</td>\n",
       "      <td>834631</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963049</th>\n",
       "      <td>2375</td>\n",
       "      <td>40186322971</td>\n",
       "      <td>559</td>\n",
       "      <td>855914</td>\n",
       "      <td>1</td>\n",
       "      <td>2.79</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963050</th>\n",
       "      <td>2375</td>\n",
       "      <td>40186322971</td>\n",
       "      <td>559</td>\n",
       "      <td>860776</td>\n",
       "      <td>2</td>\n",
       "      <td>1.58</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963051</th>\n",
       "      <td>2375</td>\n",
       "      <td>40186322971</td>\n",
       "      <td>559</td>\n",
       "      <td>872062</td>\n",
       "      <td>1</td>\n",
       "      <td>2.59</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34</td>\n",
       "      <td>81</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "1963047     2375  40186322971  559   827667         2         6.00       364   \n",
       "1963048     2375  40186322971  559   834631         1         1.69       364   \n",
       "1963049     2375  40186322971  559   855914         1         2.79       364   \n",
       "1963050     2375  40186322971  559   860776         2         1.58       364   \n",
       "1963051     2375  40186322971  559   872062         1         2.59       364   \n",
       "\n",
       "         retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "1963047        -1.78          34       81          0.0                0.0  \n",
       "1963048         0.00          34       81          0.0                0.0  \n",
       "1963049         0.00          34       81          0.0                0.0  \n",
       "1963050         0.00          34       81          0.0                0.0  \n",
       "1963051         0.00          34       81         -1.0                0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_ranker.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_preparation(data, keep_columns=[USER_COL, ITEM_COL, 'basket_id', 'quantity', 'sales_value', 'retail_disc', \n",
    "                                       'week_no', 'store_id']):\n",
    "    data = data[keep_columns].copy()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ranker_train = data_train_ranker[[USER_COL, ITEM_COL, 'basket_id', 'quantity', 'sales_value', 'retail_disc', 'week_no', 'store_id']].copy()\n",
    "#df_ranker_train = data_train_ranker[[USER_COL, ITEM_COL, 'basket_id', 'quantity', 'sales_value', 'retail_disc', 'week_no', 'store_id']].copy()\n",
    "columns = [USER_COL, ITEM_COL, 'basket_id', 'quantity', 'sales_value', 'retail_disc', 'week_no', 'store_id']\n",
    "\n",
    "df_ranker_train = df_preparation(data_train_ranker, keep_columns=columns)\n",
    "df_ranker_train['target'] = 1  # тут только покупки \n",
    "\n",
    "df_ranker_train = df_match_candidates.merge(df_ranker_train, on=[USER_COL, ITEM_COL], how='left')\n",
    "\n",
    "df_ranker_train['target'].fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    205632\n",
       "1.0     22234\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranker_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(!) На каждого юзера 50 item_id-кандидатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0975748905058236"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranker_train['target'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготавливаем фичи для обучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описательные фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_features.head(2)\n",
    "#user_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_merge_features(data, item_features, user_features):\n",
    "    data = data.merge(item_features, on='item_id', how='left')\n",
    "    data = data.merge(user_features, on='user_id', how='left')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train = df_merge_features(df_ranker_train, item_features, user_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Фичи user_id:**\n",
    "    - Средний чек\n",
    "    - Средняя сумма покупки 1 товара в каждой категории\n",
    "    - Кол-во покупок в каждой категории\n",
    "    - Частотность покупок раз/месяц\n",
    "    - Долю покупок в выходные\n",
    "    - Долю покупок утром/днем/вечером\n",
    "\n",
    "**Фичи item_id**:\n",
    "    - Кол-во покупок в неделю\n",
    "    - Среднее ол-во покупок 1 товара в категории в неделю\n",
    "    - (Кол-во покупок в неделю) / (Среднее ол-во покупок 1 товара в категории в неделю)\n",
    "    - Цена (Можно посчитать из retil_train.csv)\n",
    "    - Цена / Средняя цена товара в категории\n",
    "    \n",
    "**Фичи пары user_id - item_id**\n",
    "    - (Средняя сумма покупки 1 товара в каждой категории (берем категорию item_id)) - (Цена item_id)\n",
    "    - (Кол-во покупок юзером конкретной категории в неделю) - (Среднее кол-во покупок всеми юзерами конкретной категории в неделю)\n",
    "    - (Кол-во покупок юзером конкретной категории в неделю) / (Среднее кол-во покупок всеми юзерами конкретной категории в неделю)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поведенческие фичи\n",
    "\n",
    "##### Чтобы считать поведенческие фичи, нужно учесть все данные что были до data_val_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>week_no</th>\n",
       "      <th>store_id</th>\n",
       "      <th>target</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>...</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>1046545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>POTATOES</td>\n",
       "      <td>POTATOES RUSSET (BULK&amp;BAG)</td>\n",
       "      <td>10 LB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>999104</td>\n",
       "      <td>4.028339e+10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.69</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>82.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1194</td>\n",
       "      <td>...</td>\n",
       "      <td>REFRGRATD JUICES/DRNKS</td>\n",
       "      <td>DAIRY CASE 100% PURE JUICE - O</td>\n",
       "      <td>64OZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2375</td>\n",
       "      <td>1000753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2822</td>\n",
       "      <td>...</td>\n",
       "      <td>BEEF</td>\n",
       "      <td>SELECT BEEF</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2375</td>\n",
       "      <td>899624</td>\n",
       "      <td>4.018632e+10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>81.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>POTATOES</td>\n",
       "      <td>POTATOES RUSSET (BULK&amp;BAG)</td>\n",
       "      <td>10 LB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2375</td>\n",
       "      <td>899624</td>\n",
       "      <td>4.059502e+10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.98</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>POTATOES</td>\n",
       "      <td>POTATOES RUSSET (BULK&amp;BAG)</td>\n",
       "      <td>10 LB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id     basket_id  quantity  sales_value  retail_disc  \\\n",
       "0     2375  1046545           NaN       NaN          NaN          NaN   \n",
       "1     2375   999104  4.028339e+10       1.0         2.69        -0.15   \n",
       "2     2375  1000753           NaN       NaN          NaN          NaN   \n",
       "3     2375   899624  4.018632e+10       4.0        15.96         0.00   \n",
       "4     2375   899624  4.059502e+10       2.0         5.98        -2.00   \n",
       "\n",
       "   week_no  store_id  target  manufacturer  ...          commodity_desc  \\\n",
       "0      NaN       NaN     0.0            69  ...                POTATOES   \n",
       "1     82.0     364.0     1.0          1194  ...  REFRGRATD JUICES/DRNKS   \n",
       "2      NaN       NaN     0.0          2822  ...                    BEEF   \n",
       "3     81.0     364.0     1.0            69  ...                POTATOES   \n",
       "4     85.0     364.0     1.0            69  ...                POTATOES   \n",
       "\n",
       "               sub_commodity_desc curr_size_of_product age_desc  \\\n",
       "0      POTATOES RUSSET (BULK&BAG)                10 LB      NaN   \n",
       "1  DAIRY CASE 100% PURE JUICE - O                 64OZ      NaN   \n",
       "2                     SELECT BEEF                           NaN   \n",
       "3      POTATOES RUSSET (BULK&BAG)                10 LB      NaN   \n",
       "4      POTATOES RUSSET (BULK&BAG)                10 LB      NaN   \n",
       "\n",
       "  marital_status_code income_desc homeowner_desc hh_comp_desc  \\\n",
       "0                 NaN         NaN            NaN          NaN   \n",
       "1                 NaN         NaN            NaN          NaN   \n",
       "2                 NaN         NaN            NaN          NaN   \n",
       "3                 NaN         NaN            NaN          NaN   \n",
       "4                 NaN         NaN            NaN          NaN   \n",
       "\n",
       "  household_size_desc kid_category_desc  \n",
       "0                 NaN               NaN  \n",
       "1                 NaN               NaN  \n",
       "2                 NaN               NaN  \n",
       "3                 NaN               NaN  \n",
       "4                 NaN               NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranker_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!! Пока выполните нотбук без этих строк, потом вернитесь и запустите их, обучите ранкер и посмотрите на метрики с ранжированием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_add_features(data, initial_df, ITEM_COL='item_id', USER_COL='user_id'):\n",
    "    data = data.merge(initial_df.groupby(by=ITEM_COL).agg('sales_value').sum().rename('total_item_sales_value'), how='left',on=ITEM_COL)\n",
    "    data = data.merge(initial_df.groupby(by=ITEM_COL).agg('quantity').sum().rename('total_quantity_value'), how='left',on=ITEM_COL)\n",
    "    data = data.merge(initial_df.groupby(by=ITEM_COL).agg(USER_COL).count().rename('item_freq'), how='left',on=ITEM_COL)\n",
    "    #data = data.merge(initial_df.groupby(by=USER_COL).agg(USER_COL).count().rename('user_freq'), how='left',on=USER_COL)\n",
    "    #data = data.merge(initial_df.groupby(by=USER_COL).agg('sales_value').sum().rename('total_user_sales_value'), how='left',on=USER_COL)\n",
    "    data = data.merge(initial_df.groupby(by=ITEM_COL).agg('quantity').sum().rename('item_quantity_per_week')/initial_df.week_no.nunique(), how='left',on=ITEM_COL)\n",
    "    data = data.merge(initial_df.groupby(by=ITEM_COL).agg('quantity').sum().rename('item_quantity_per_user')/initial_df.user_id.nunique(), how='left',on=ITEM_COL)\n",
    "    #data = data.merge(initial_df.groupby(by=USER_COL).agg('quantity').sum().rename('user_quantity_per_week')/initial_df.week_no.nunique(), how='left',on=USER_COL)\n",
    "    #data = data.merge(initial_df.groupby(by=ITEM_COL).agg('quantity').sum().rename('item_quantity_per_basket')/initial_df.basket_id.nunique(), how='left',on=ITEM_COL)\n",
    "    #data = data.merge(initial_df.groupby(by=ITEM_COL).agg('quantity').sum().rename('user_quantity_per_baskter')/initial_df.basket_id.nunique(), how='left',on=USER_COL)\n",
    "    #data = data.merge(initial_df.groupby(by=ITEM_COL).agg(USER_COL).count().rename('item_freq_per_basket')/initial_df.basket_id.nunique(), how='left',on=ITEM_COL)\n",
    "    #data = data.merge(initial_df.groupby(by=USER_COL).agg(USER_COL).count().rename('user_freq_per_basket')/initial_df.basket_id.nunique(), how='left',on=USER_COL)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg('sales_value').sum().rename('total_item_sales_value'), how='left',on=ITEM_COL)\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg('quantity').sum().rename('total_quantity_value'), how='left',on=ITEM_COL)\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg(USER_COL).count().rename('item_freq'), how='left',on=ITEM_COL)\n",
    "#df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=USER_COL).agg(USER_COL).count().rename('user_freq'), how='left',on=USER_COL)\n",
    "#df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=USER_COL).agg('sales_value').sum().rename('total_user_sales_value'), how='left',on=USER_COL)\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg('quantity').sum().rename('item_quantity_per_week')/df_join_train_matcher.week_no.nunique(), how='left',on=ITEM_COL)\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg('quantity').sum().rename('item_quantity_per_user')/df_join_train_matcher.user_id.nunique(), how='left',on=ITEM_COL)\n",
    "\n",
    "#df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=USER_COL).agg('quantity').sum().rename('user_quantity_per_week')/df_join_train_matcher.week_no.nunique(), how='left',on=USER_COL)\n",
    "\n",
    "#df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg('quantity').sum().rename('item_quantity_per_basket')/df_join_train_matcher.basket_id.nunique(), how='left',on=ITEM_COL)\n",
    "\n",
    "#df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=USER_COL).agg('quantity').sum().rename('user_quantity_per_baskter')/df_join_train_matcher.basket_id.nunique(), how='left',on=USER_COL)\n",
    "\n",
    "#df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg(USER_COL).count().rename('item_freq_per_basket')/df_join_train_matcher.basket_id.nunique(), how='left',on=ITEM_COL)\n",
    "\n",
    "#df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=USER_COL).agg(USER_COL).count().rename('user_freq_per_basket')/df_join_train_matcher.basket_id.nunique(), how='left',on=USER_COL)\n",
    "\"\"\"\n",
    "\n",
    "df_ranker_train = df_add_features(df_ranker_train, df_join_train_matcher, ITEM_COL=ITEM_COL, USER_COL=USER_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_ranker_train.drop('target', axis=1)\n",
    "y_train = df_ranker_train[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_preparation(data):\n",
    "    data['quantity'].fillna(value=0, inplace=True)\n",
    "    data['sales_value'].fillna(value=0, inplace=True)\n",
    "    data['retail_disc'].fillna(value=0, inplace=True)\n",
    "    data['age_desc'].fillna(value='19-65+', inplace=True)\n",
    "    data['marital_status_code'].fillna( value='C', inplace=True)\n",
    "    data['income_desc'].fillna( value='0-250K+', inplace=True)\n",
    "    data['homeowner_desc'].fillna( value='Unknown', inplace=True)\n",
    "    data['hh_comp_desc'].fillna( value='Unknown', inplace=True)\n",
    "    data['household_size_desc'].fillna( value='Unknown', inplace=True)\n",
    "    data['kid_category_desc'].fillna( value='None/Unknown', inplace=True)\n",
    "    data['store_id'] = X_train['store_id'].astype(str)\n",
    "    data['basket_id'] = X_train['basket_id'].astype(str)\n",
    "    data.replace('nan', 'U', inplace=True)\n",
    "    data['week_no'].fillna(value=0, inplace=True)\n",
    "    data['week_no'] = data['week_no'].astype(int)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data_preparation(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"unimportant_features = ['basket_id']\\nX_train.drop(columns = unimportant_features, inplace=True)\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unimportant_features = ['brand', 'commodity_desc', 'sub_commodity_desc', 'curr_size_of_product', \n",
    "#                        'age_desc', 'marital_status_code', 'income_desc', 'homeowner_desc', 'hh_comp_desc', \n",
    "#                        'household_size_desc', 'kid_category_desc', 'item_quantity_per_week'\n",
    "#                       ]\n",
    "\"\"\"unimportant_features = ['basket_id']\n",
    "X_train.drop(columns = unimportant_features, inplace=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = [col for col in X_train.columns if (X_train[col].dtype == 'int64') or (X_train[col].dtype == 'float64')]\n",
    "num_feats = set(num_feats) - set(['manufacturer','user_id', 'item_id', 'week_no'])\n",
    "#num_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = X_train.columns[0:].tolist()\n",
    "cat_feats = list(set(cat_feats) - set(num_feats))\n",
    "#cat_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train[cat_feats] = X_train[cat_feats].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели ранжирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# week for validation\n",
    "#data = X_train\n",
    "#data['target'] = y_train\n",
    "\n",
    "#X_val = data[data['week_no'] >= data['week_no'].max() - 2]\n",
    "#X_train = data[data['week_no'] < data['week_no'].max() - 2]\n",
    "\n",
    "#y_train = X_train[['target']]\n",
    "#X_train = X_train.drop('target', axis=1)\n",
    "\n",
    "#y_val = X_val[['target']]\n",
    "#X_val = X_val.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3df04ad8a8451b937626460bb1609b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fa11724c340>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature_weight = {\"week_no\":0.005,\"store_id\":0.01, \"quantity\":0.01, \"sales_value\":0.01, \n",
    "#                  \"retail_disc\":0.01, \"basket_id\":0.11, \"retail_disc\":0.005, \"item_id\":0.1, \"user_id\":0.1}\n",
    "feature_weight = {\"week_no\":0.08, \"sales_value\":0.083, \"quantity\":0.084, \"store_id\":0.08,\n",
    "                  \"retail_disc\":0.5, 'basket_id':0}\n",
    "#feature_weight = {\"quantity\":1}\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=70,\n",
    "    learning_rate=0.05,\n",
    "    depth=10,\n",
    "    random_seed=12,\n",
    "    logging_level='Silent',\n",
    "    cat_features=cat_feats,\n",
    "    feature_weights = feature_weight,\n",
    "    custom_metric=['Logloss', 'Precision', 'F1', 'Recall']\n",
    ")\n",
    "#use_best_model=True\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    plot=True\n",
    ")\n",
    "#eval_set=(X_val, y_val),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_feature_importance(prettified = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from hyperopt import fmin, tpe, hp, Trials\\nn_iter = 30\\nrandom_st = 12\\n\\ndef score_func(params, data=df_ranker_train, X_train=X_train,\\n               y_train=y_train, X_val=X_val, y_val=y_val,\\n               data_val=item_feat_lightfm, random_state_val=random_st,\\n               TOPK_PRECISION = 5\\n              ):\\n    \\n    # the function gets a set of variable parameters in \"param\"\\n    model_params = {\\'iterations\\': int(params[\\'iterations\\']),\\n                    \\'learning_rate\\': params[\\'learning_rate\\'],\\n                    \\'depth\\': int(params[\\'depth\\']),\\n                    \\'logging_level\\': params[\\'logging_level\\'],\\n                    \\'cat_features\\': params[\\'cat_features\\'],\\n                    \\'feature_weights\\': f\\'({\",\".join([str(item) for item in params[\\'feature_weights\\']])})\\'\\n                   }\\n    \\n    # we use this params to create a new CatBoost model\\n    model = CatBoostClassifier(random_seed=random_state_val, **model_params)\\n    \\n    #use_best_model=True\\n    model.fit(X_train, y_train, plot=False)\\n    \\n    train_preds = model.predict_proba(X_train)\\n    data[\\'proba_item_purchase\\'] = train_preds[:,1]\\n    result_eval_ranker = data_val_ranker.groupby(USER_COL)[ITEM_COL].unique().reset_index()\\n    result_eval_ranker.columns=[USER_COL, ACTUAL_COL]\\n    def rerank(user_id):\\n    return df_ranker_predict[df_ranker_predict[USER_COL]==user_id].sort_values(\\'proba_item_purchase\\', ascending=False).head(5).item_id.tolist()\\n    result_eval_ranker[\\'reranked_als_rec\\'] = result_eval_ranker[USER_COL].apply(lambda user_id: rerank(user_id))\\n    current_precision = sorted(calc_precision(result_eval_ranker, TOPK_PRECISION), key=lambda x: x[1], reverse=True)[0][1]\\n\\n    # precision\\n    if current_precision > 0:\\n        score = 1/current_precision\\n    else:\\n        score = 1e100\\n    \\n    return score\\n\\nparam={\\'iterations\\': hp.uniform(\\'iterations\\', 10, 100),\\n       \\'learning_rate\\': hp.uniform(\\'learning_rate\\', 0.01, 0.1),\\n       \\'depth\\': hp.uniform(\\'depth\\', 1, 12),\\n       \\'logging_level\\': \\'Silent\\',\\n       \\'cat_features\\': cat_feats,\\n       \\'feature_weights\\': [hp.uniform(\\'feature_weights\\', 0.0, 1) for i in range(len(X_train.columns))]\\n      }\\n\\n%%time\\n\\nbest=fmin(score_func, # function to optimize\\n          space=param, \\n          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\\n          max_evals=n_iter, # maximum number of iterations\\n         )\\n# computing the score on the test set\\nmodel = CatBoostClassifier(random_state=random_st, no_components=int(best[\\'no_components\\']),\\n                learning_rate=best[\\'learning_rate\\'],item_alpha=best[\\'item_alpha\\'],\\n                user_alpha=best[\\'user_alpha\\'], loss=\\'warp\\'\\n               )'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from hyperopt import fmin, tpe, hp, Trials\n",
    "n_iter = 30\n",
    "random_st = 12\n",
    "\n",
    "def score_func(params, data=df_ranker_train, X_train=X_train,\n",
    "               y_train=y_train, X_val=X_val, y_val=y_val,\n",
    "               data_val=item_feat_lightfm, random_state_val=random_st,\n",
    "               TOPK_PRECISION = 5\n",
    "              ):\n",
    "    \n",
    "    # the function gets a set of variable parameters in \"param\"\n",
    "    model_params = {'iterations': int(params['iterations']),\n",
    "                    'learning_rate': params['learning_rate'],\n",
    "                    'depth': int(params['depth']),\n",
    "                    'logging_level': params['logging_level'],\n",
    "                    'cat_features': params['cat_features'],\n",
    "                    'feature_weights': f'({\",\".join([str(item) for item in params['feature_weights']])})'\n",
    "                   }\n",
    "    \n",
    "    # we use this params to create a new CatBoost model\n",
    "    model = CatBoostClassifier(random_seed=random_state_val, **model_params)\n",
    "    \n",
    "    #use_best_model=True\n",
    "    model.fit(X_train, y_train, plot=False)\n",
    "    \n",
    "    train_preds = model.predict_proba(X_train)\n",
    "    data['proba_item_purchase'] = train_preds[:,1]\n",
    "    result_eval_ranker = data_val_ranker.groupby(USER_COL)[ITEM_COL].unique().reset_index()\n",
    "    result_eval_ranker.columns=[USER_COL, ACTUAL_COL]\n",
    "    def rerank(user_id):\n",
    "    return df_ranker_predict[df_ranker_predict[USER_COL]==user_id].sort_values('proba_item_purchase', ascending=False).head(5).item_id.tolist()\n",
    "    result_eval_ranker['reranked_als_rec'] = result_eval_ranker[USER_COL].apply(lambda user_id: rerank(user_id))\n",
    "    current_precision = sorted(calc_precision(result_eval_ranker, TOPK_PRECISION), key=lambda x: x[1], reverse=True)[0][1]\n",
    "\n",
    "    # precision\n",
    "    if current_precision > 0:\n",
    "        score = 1/current_precision\n",
    "    else:\n",
    "        score = 1e100\n",
    "    \n",
    "    return score\n",
    "\n",
    "param={'iterations': hp.uniform('iterations', 10, 100),\n",
    "       'learning_rate': hp.uniform('learning_rate', 0.01, 0.1),\n",
    "       'depth': hp.uniform('depth', 1, 12),\n",
    "       'logging_level': 'Silent',\n",
    "       'cat_features': cat_feats,\n",
    "       'feature_weights': [hp.uniform('feature_weights', 0.0, 1) for i in range(len(X_train.columns))]\n",
    "      }\n",
    "\n",
    "%%time\n",
    "\n",
    "best=fmin(score_func, # function to optimize\n",
    "          space=param, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals=n_iter, # maximum number of iterations\n",
    "         )\n",
    "# computing the score on the test set\n",
    "model = CatBoostClassifier(random_state=random_st, no_components=int(best['no_components']),\n",
    "                learning_rate=best['learning_rate'],item_alpha=best['item_alpha'],\n",
    "                user_alpha=best['user_alpha'], loss='warp'\n",
    "               )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_preds = model.predict_proba(data.drop('target', axis=1))\n",
    "train_preds = model.predict_proba(X_train)\n",
    "df_ranker_predict = df_ranker_train.copy()\n",
    "df_ranker_predict['proba_item_purchase'] = train_preds[:,1]\n",
    "#df_ranker_predict.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подведем итоги\n",
    "\n",
    "    Мы обучили модель ранжирования на покупках из сета data_train_ranker и на кандитатах от als_recommendations, что является тренировочным сетом, и теперь наша задача предсказать и оценить именно на тестовом сете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[821867, 834484, 856942, 865456, 889248, 90795...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[835476, 851057, 872021, 878302, 879948, 90963...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [821867, 834484, 856942, 865456, 889248, 90795...\n",
       "1        3  [835476, 851057, 872021, 878302, 879948, 90963..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_eval_ranker = data_val_ranker.groupby(USER_COL)[ITEM_COL].unique().reset_index()\n",
    "result_eval_ranker.columns=[USER_COL, ACTUAL_COL]\n",
    "result_eval_ranker.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval matching on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50 s, sys: 1.7 s, total: 51.7 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_eval_ranker['own_rec'] = recommended_items(0, result_eval_ranker[USER_COL], N_PREDICT, recommender.get_own_recommendations)\n",
    "result_eval_ranker['als_rec'] = recommended_items(0, result_eval_ranker[USER_COL], N_PREDICT, recommender.get_als_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TOPK_PRECISION = 5'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'TOPK_PRECISION = {TOPK_PRECISION}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# померяем precision только модели матчинга, чтобы понимать влияение ранжирования на метрики\n",
    "\n",
    "#sorted(calc_precision(result_eval_ranker, TOPK_PRECISION), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval re-ranked matched result on test dataset\n",
    "    Вспомним df_match_candidates сет, который был получен own_recommendations на юзерах, набор пользователей мы фиксировали и он одинаков, значи и прогноз одинаков, поэтому мы можем использовать этот датафрейм для переранжирования.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(user_id, df = df_ranker_predict):\n",
    "    return df[df[USER_COL]==user_id].sort_values('proba_item_purchase', ascending=False).head(5).item_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('reranked_als_rec', 0.9606511862695566)\n",
      "('als_rec', 0.13084300858152378)\n",
      "('own_rec', 0.02796567390206973)\n",
      "TOPK_PRECISION = 5\n"
     ]
    }
   ],
   "source": [
    "data_val_ranker = df_preparation(data_val_ranker, keep_columns=columns)\n",
    "data_val_ranker = df_merge_features(data_val_ranker, item_features, user_features)\n",
    "data_val_ranker = df_add_features(data_val_ranker, df_join_train_matcher, ITEM_COL=ITEM_COL, USER_COL=USER_COL)\n",
    "data_val_ranker = train_data_preparation(data_val_ranker)\n",
    "\n",
    "\n",
    "train_preds = model.predict_proba(data_val_ranker)\n",
    "data_val_ranker['proba_item_purchase'] = train_preds[:,1]\n",
    "\n",
    "result_eval_ranker['reranked_als_rec'] = result_eval_ranker[USER_COL].apply(lambda user_id: rerank(user_id, data_val_ranker))\n",
    "print(*sorted(calc_precision(result_eval_ranker, TOPK_PRECISION), key=lambda x: x[1], reverse=True),  f'TOPK_PRECISION = {TOPK_PRECISION}', sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision@5 >= 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# смотрим на метрики выше и сравниваем что с ранжированием и без, добавляем фичи и то же смотрим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка на тесте для выполнения курсового проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK_PRECISION = 5\n",
    "\n",
    "df_test = pd.read_csv('retail_test1.csv')\n",
    "#df_transactions = pd.read_csv('retail_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = df_test[df_test.user_id.isin(common_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340</td>\n",
       "      <td>41652823310</td>\n",
       "      <td>664</td>\n",
       "      <td>912987</td>\n",
       "      <td>1</td>\n",
       "      <td>8.49</td>\n",
       "      <td>446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>588</td>\n",
       "      <td>41652838477</td>\n",
       "      <td>664</td>\n",
       "      <td>1024426</td>\n",
       "      <td>1</td>\n",
       "      <td>6.29</td>\n",
       "      <td>388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2070</td>\n",
       "      <td>41652857291</td>\n",
       "      <td>664</td>\n",
       "      <td>995242</td>\n",
       "      <td>5</td>\n",
       "      <td>9.10</td>\n",
       "      <td>311</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>46</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1602</td>\n",
       "      <td>41665647035</td>\n",
       "      <td>664</td>\n",
       "      <td>827939</td>\n",
       "      <td>1</td>\n",
       "      <td>7.99</td>\n",
       "      <td>334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1741</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1602</td>\n",
       "      <td>41665647035</td>\n",
       "      <td>664</td>\n",
       "      <td>927712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>334</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1741</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     1340  41652823310  664   912987         1         8.49       446   \n",
       "1      588  41652838477  664  1024426         1         6.29       388   \n",
       "2     2070  41652857291  664   995242         5         9.10       311   \n",
       "3     1602  41665647035  664   827939         1         7.99       334   \n",
       "4     1602  41665647035  664   927712         1         0.59       334   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0          0.0          52       96          0.0                0.0  \n",
       "1          0.0           8       96          0.0                0.0  \n",
       "2         -0.6          46       96          0.0                0.0  \n",
       "3          0.0        1741       96          0.0                0.0  \n",
       "4         -0.4        1741       96          0.0                0.0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[880007, 883616, 931136, 938004, 940947, 94726...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[820165, 820291, 826784, 826835, 829009, 85784...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [880007, 883616, 931136, 938004, 940947, 94726...\n",
       "1        2  [820165, 820291, 826784, 826835, 829009, 85784..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test = df_test.groupby(USER_COL)[ITEM_COL].unique().reset_index()\n",
    "result_test.columns=[USER_COL, ACTUAL_COL]\n",
    "result_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_preparation(df_test, keep_columns=columns)\n",
    "df_test = df_merge_features(df_test, item_features, user_features)\n",
    "df_test = df_add_features(df_test, df_join_train_matcher, ITEM_COL=ITEM_COL, USER_COL=USER_COL)\n",
    "df_test = train_data_preparation(df_test)\n",
    "\n",
    "train_preds = model.predict_proba(df_test)\n",
    "df_test['proba_item_purchase'] = train_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(calc_precision(result_test, TOPK_PRECISION), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test['reranked_als_rec'] = result_test[USER_COL].apply(lambda user_id: rerank(user_id, df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('reranked_als_rec', 0.9564456233421706)\n",
      "TOPK_PRECISION = 5\n"
     ]
    }
   ],
   "source": [
    "print(*sorted(calc_precision(result_test, TOPK_PRECISION), key=lambda x: x[1], reverse=True),  f'TOPK_PRECISION = {TOPK_PRECISION}', sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
